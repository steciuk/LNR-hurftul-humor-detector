{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import nltk\n",
    "from enum import Enum\n",
    "import re\n",
    "import spacy\n",
    "from spacy.tokens import Token\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from gensim.models import Word2Vec\n",
    "from gensim.models import KeyedVectors\n",
    "import numpy as np"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_PATH = os.path.join(os.getcwd(), 'data', 'train.csv')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's rename the columns to make them easier to work with."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>humor</th>\n",
       "      <th>woman</th>\n",
       "      <th>lgbtiq</th>\n",
       "      <th>race</th>\n",
       "      <th>gordofobia</th>\n",
       "      <th>mean</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>index</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>MENTION Ya estará colocada en algún chiringuit...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Sin querer, hoy le dije “Hola” a una feminista...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>En este capítulo, que se transmitió en el Cana...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>MENTION MENTION MENTION Concuerdo contigo en e...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>– ¡No es no! ¡En mi cuerpo mando yo!\\r\\n– ¡Así...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    text  humor  woman  \\\n",
       "index                                                                    \n",
       "9      MENTION Ya estará colocada en algún chiringuit...      0      1   \n",
       "22     Sin querer, hoy le dije “Hola” a una feminista...      1      1   \n",
       "30     En este capítulo, que se transmitió en el Cana...      0      0   \n",
       "40     MENTION MENTION MENTION Concuerdo contigo en e...      0      0   \n",
       "45     – ¡No es no! ¡En mi cuerpo mando yo!\\r\\n– ¡Así...      1      1   \n",
       "\n",
       "       lgbtiq  race  gordofobia  mean  \n",
       "index                                  \n",
       "9           0     0           0   3.4  \n",
       "22          0     0           0   3.8  \n",
       "30          1     0           0   2.2  \n",
       "40          1     0           0   3.8  \n",
       "45          0     0           0   2.2  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>humor</th>\n",
       "      <th>woman</th>\n",
       "      <th>lgbtiq</th>\n",
       "      <th>race</th>\n",
       "      <th>gordofobia</th>\n",
       "      <th>mean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>2671.000000</td>\n",
       "      <td>2671.000000</td>\n",
       "      <td>2671.000000</td>\n",
       "      <td>2671.000000</td>\n",
       "      <td>2671.000000</td>\n",
       "      <td>2671.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.325346</td>\n",
       "      <td>0.483714</td>\n",
       "      <td>0.227256</td>\n",
       "      <td>0.248596</td>\n",
       "      <td>0.080120</td>\n",
       "      <td>3.053126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.468592</td>\n",
       "      <td>0.499828</td>\n",
       "      <td>0.419138</td>\n",
       "      <td>0.432280</td>\n",
       "      <td>0.271529</td>\n",
       "      <td>0.809173</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.400000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.400000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.600000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>5.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             humor        woman       lgbtiq         race   gordofobia  \\\n",
       "count  2671.000000  2671.000000  2671.000000  2671.000000  2671.000000   \n",
       "mean      0.325346     0.483714     0.227256     0.248596     0.080120   \n",
       "std       0.468592     0.499828     0.419138     0.432280     0.271529   \n",
       "min       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "25%       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "50%       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "75%       1.000000     1.000000     0.000000     0.000000     0.000000   \n",
       "max       1.000000     1.000000     1.000000     1.000000     1.000000   \n",
       "\n",
       "              mean  \n",
       "count  2671.000000  \n",
       "mean      3.053126  \n",
       "std       0.809173  \n",
       "min       0.400000  \n",
       "25%       2.400000  \n",
       "50%       3.000000  \n",
       "75%       3.600000  \n",
       "max       5.000000  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data_df = pd.read_csv(TRAIN_PATH, index_col='index')\n",
    "data_df = data_df.rename(columns={\n",
    "    'tweet': 'text',\n",
    "    'prejudice_woman': 'woman',\n",
    "    'prejudice_lgbtiq': 'lgbtiq',\n",
    "    'prejudice_inmigrant_race': 'race',\n",
    "    'mean_prejudice': 'mean',\n",
    "})\n",
    "\n",
    "data_df = data_df.sort_index()\n",
    "\n",
    "display(data_df.head(5))\n",
    "display(data_df.describe())\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's load the spacy model\n",
    "\n",
    "es_core_news_md jest średniej wielkości modelem, który zawiera informacje o podstawowych częściach mowy, frazach, nazwach własnych, a także informacje semantyczne. Dobry do dokładniej analizy języka naturalnego, ale nie bardzo dużej ilości informacji semantycznych. -> nie interesuje nas \n",
    "\n",
    "es_core_news_lg to dużo większy model, który zawiera dużo więcej informacji semantycznych, takich jak modele kontekstowe, dobry wybór, jeśli potrzeba bardzo dokładnej analizy języka naturalnego + praca z dużymi zbiorami danych tekstowych. ->> jest chyba najlepszy\n",
    "\n",
    "es_dep_news_trf to model oparty na sieciach neuronowych, który zajmuje się głównie analizą składniową języka naturalnego, dobry dla zależności syntaktycznych między słowami, takie jak podmioty, dopełnienia, itp.\n",
    "\n",
    "\n",
    "Dla wykrywaniu humoru -> modele specjalnie zaprojektowane do analizy sentymentu, takich jak TextBlob lub VADER - dostarczają informacji o nacechowaniu emocjonalnym tekstu. (trzeba by przetłumaczyć na jezyk ang aby działały)\n",
    "\n",
    "https://datascience.stackexchange.com/questions/6691/sentiment-analysis-model-for-spanish -> ANALIZA SENTYMENTU PO HISZPANSKU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "SPACY_MODEL = \"es_core_news_sm\"\n",
    "ES_CORE_MODEL = \"es_core_news_lg\"\n",
    "# TODO: Try other spanish spacy models: es_core_news_md, es_core_news_lg, es_dep_news_trf\n",
    "\n",
    "try:\n",
    "    nlp = spacy.load(SPACY_MODEL)\n",
    "except OSError:\n",
    "    spacy.cli.download(SPACY_MODEL)\n",
    "    nlp = spacy.load(SPACY_MODEL)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By using the default pipeline of the spacy model, we can get tokens with information about their part of speech, lemma, whether they are a stop word, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>humor</th>\n",
       "      <th>woman</th>\n",
       "      <th>lgbtiq</th>\n",
       "      <th>race</th>\n",
       "      <th>gordofobia</th>\n",
       "      <th>mean</th>\n",
       "      <th>tokens</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>index</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>MENTION Ya estará colocada en algún chiringuit...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3.4</td>\n",
       "      <td>[MENTION, Ya, estará, colocada, en, algún, chi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Sin querer, hoy le dije “Hola” a una feminista...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3.8</td>\n",
       "      <td>[Sin, querer, ,, hoy, le, dije, “, Hola, ”, a,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>En este capítulo, que se transmitió en el Cana...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.2</td>\n",
       "      <td>[En, este, capítulo, ,, que, se, transmitió, e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>MENTION MENTION MENTION Concuerdo contigo en e...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3.8</td>\n",
       "      <td>[MENTION, MENTION, MENTION, Concuerdo, contigo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>– ¡No es no! ¡En mi cuerpo mando yo!\\r\\n– ¡Así...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.2</td>\n",
       "      <td>[–, ¡, No, es, no, !, ¡, En, mi, cuerpo, mando...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    text  humor  woman  \\\n",
       "index                                                                    \n",
       "9      MENTION Ya estará colocada en algún chiringuit...      0      1   \n",
       "22     Sin querer, hoy le dije “Hola” a una feminista...      1      1   \n",
       "30     En este capítulo, que se transmitió en el Cana...      0      0   \n",
       "40     MENTION MENTION MENTION Concuerdo contigo en e...      0      0   \n",
       "45     – ¡No es no! ¡En mi cuerpo mando yo!\\r\\n– ¡Así...      1      1   \n",
       "\n",
       "       lgbtiq  race  gordofobia  mean  \\\n",
       "index                                   \n",
       "9           0     0           0   3.4   \n",
       "22          0     0           0   3.8   \n",
       "30          1     0           0   2.2   \n",
       "40          1     0           0   3.8   \n",
       "45          0     0           0   2.2   \n",
       "\n",
       "                                                  tokens  \n",
       "index                                                     \n",
       "9      [MENTION, Ya, estará, colocada, en, algún, chi...  \n",
       "22     [Sin, querer, ,, hoy, le, dije, “, Hola, ”, a,...  \n",
       "30     [En, este, capítulo, ,, que, se, transmitió, e...  \n",
       "40     [MENTION, MENTION, MENTION, Concuerdo, contigo...  \n",
       "45     [–, ¡, No, es, no, !, ¡, En, mi, cuerpo, mando...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Tokenize text\n",
    "parsed_df = data_df.copy()\n",
    "parsed_df['tokens'] = list(nlp.pipe(parsed_df['text']))\n",
    "parsed_df['tokens'] = parsed_df['tokens'].apply(lambda x: [token for token in x])\n",
    "display(parsed_df.head(5))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text:  algún\n",
      "Lemma:  alguno\n",
      "POS:  DET\n",
      "Tag:  DET\n",
      "Dep:  det\n",
      "Shape:  xxxx\n",
      "Is alpha:  True\n",
      "Is stop:  True\n"
     ]
    }
   ],
   "source": [
    "# Show some data about a token\n",
    "token: Token = parsed_df['tokens'].iloc[0][5]\n",
    "print(\"Text: \", token.text)\n",
    "print(\"Lemma: \", token.lemma_)\n",
    "print(\"POS: \", token.pos_)\n",
    "print(\"Tag: \", token.tag_)\n",
    "print(\"Dep: \", token.dep_)\n",
    "print(\"Shape: \", token.shape_)\n",
    "print(\"Is alpha: \", token.is_alpha)\n",
    "print(\"Is stop: \", token.is_stop)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Token filtering utility\n",
    "Let's create utility functions to filter the tokens based on their attributes. We can easily use these functions to filter the tokens, build and experiment with different representations of the data in the next steps of the project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "EMOJI_PATTERN = re.compile(\n",
    "    \"[\"\n",
    "    + \"\\U0001F600-\\U0001F64F\"\n",
    "    + \"\\U0001F300-\\U0001F5FF\"\n",
    "    + \"\\U0001F680-\\U0001F6FF\"\n",
    "    + \"\\U0001F1E0-\\U0001F1FF\"\n",
    "    + \"\\U00002500-\\U00002BEF\"\n",
    "    + \"\\U00002702-\\U000027B0\"\n",
    "    + \"\\U00002702-\\U000027B0\"\n",
    "    + \"\\U000024C2-\\U0001F251\"\n",
    "    + \"\\U0001f926-\\U0001f937\"\n",
    "    + \"\\U00010000-\\U0010ffff\"\n",
    "    + \"\\u2640-\\u2642\"\n",
    "    + \"\\u2600-\\u2B55\"\n",
    "    + \"\\u200d\"\n",
    "    + \"\\u23cf\"\n",
    "    + \"\\u23e9\"\n",
    "    + \"\\u231a\"\n",
    "    + \"\\ufe0f\"\n",
    "    + \"\\u3030\"\n",
    "    + \"]+\",\n",
    "    flags=re.UNICODE,\n",
    ")\n",
    "\n",
    "try:\n",
    "    STOPWORDS = nltk.corpus.stopwords.words(\"spanish\")\n",
    "except LookupError:\n",
    "    nltk.download(\"stopwords\")\n",
    "    STOPWORDS = nltk.corpus.stopwords.words(\"spanish\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "FILTER_FUNC = {\n",
    "    \"punct\": lambda token: token.is_punct,\n",
    "    \"stopwords\": lambda token: token.text.lower() in STOPWORDS,\n",
    "    \"emoji\": lambda token: EMOJI_PATTERN.match(token.text),\n",
    "    \"number\": lambda token: token.like_num,\n",
    "    \"newline\": lambda token: re.match(r\"\\n+\", token.text),\n",
    "    \"space\": lambda token: token.is_space and not re.match(r\"\\n+\", token.text),\n",
    "    \"tags\": lambda token: token.text in [\"MENTION\", \"HASHTAG\", \"URL\"]\n",
    "}\n",
    "\n",
    "class Filter(Enum):\n",
    "    PUNCT = \"punct\"\n",
    "    STOPWORDS = \"stopwords\"\n",
    "    EMOJI = \"emoji\"\n",
    "    NUMBER = \"number\"\n",
    "    NEWLINE = \"newline\"\n",
    "    SPACE = \"space\"\n",
    "    TAGS = \"tags\"\n",
    "\n",
    "\n",
    "def filter_tokens(series: pd.Series, filters: list[Filter]) -> pd.Series:\n",
    "    '''\n",
    "    Filters a series of tokens using the given filters.\n",
    "    args:\n",
    "        series: a series of lists of tokens\n",
    "        filters: a list of filters to apply\n",
    "    returns:\n",
    "        a series of lists of tokens\n",
    "    '''\n",
    "    return series.apply(\n",
    "        lambda tokens: [token for token in tokens if not any([FILTER_FUNC[filter.value](token) for filter in filters])]\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Expected: '\n",
      "\n",
      "', got: '\n",
      "\n",
      "'\n",
      "Test passed!\n",
      "Expected: '\n",
      "', got: '\n",
      "'\n",
      "Expected: '\n",
      "', got: '\n",
      "'\n",
      "Expected: '\n",
      "', got: '\n",
      "'\n",
      "Expected: '\n",
      "', got: '\n",
      "'\n",
      "Expected: 'HASHTAG', got: '\n",
      "\n",
      "'\n",
      "Expected: '   ', got: 'HASHTAG'\n",
      "Expected: 'feminismo', got: '   '\n",
      "Expected: '  ', got: 'feminismo'\n",
      "Expected: '#', got: '  '\n",
      "Expected: '  \n",
      "', got: '  \n",
      "'\n",
      "Expected: '\n",
      "', got: '\n",
      "'\n",
      "Expected: '\n",
      "', got: '\n",
      "'\n",
      "Test passed!\n"
     ]
    }
   ],
   "source": [
    "def test_filter_tokens(result, expected):\n",
    "    error = False\n",
    "    for token, expected_token in zip(result, expected):\n",
    "        try:\n",
    "            assert token.text == expected_token\n",
    "        except AssertionError:\n",
    "            print(f\"Expected: '{expected_token}', got: '{token.text}'\")\n",
    "            error = True\n",
    "\n",
    "    if not error:\n",
    "        print(\"Test passed!\")\n",
    "\n",
    "# test Filter.PUNCT\n",
    "result = filter_tokens(parsed_df['tokens'], [Filter.PUNCT]).loc[22]\n",
    "expected = ['Sin', 'querer', 'hoy', 'le', 'dije', 'Hola', 'a', 'una', 'feminista', 'El', 'juicio', 'es', 'mañana', '\\n\\n', 'HASHTAG', '   ', 'feminismo', '  ']\n",
    "test_filter_tokens(result, expected)\n",
    "\n",
    "# test Filter.STOPWORDS\n",
    "result = filter_tokens(parsed_df['tokens'], [Filter.STOPWORDS]).loc[9]\n",
    "expected = ['MENTION', 'colocada', 'algún', 'chiringuito', 'feminazi']\n",
    "test_filter_tokens(result, expected)\n",
    "\n",
    "# test Filter.EMOJI\n",
    "result = filter_tokens(parsed_df['tokens'], [Filter.EMOJI]).loc[75]\n",
    "expected = ['Demasiadas', 'mujeres', ',', 'demasiadas', 'mujeres', '\\n', 'URL']\n",
    "test_filter_tokens(result, expected)\n",
    "\n",
    "# test Filter.NUMBER\n",
    "result = filter_tokens(parsed_df['tokens'], [Filter.NUMBER]).loc[5245]\n",
    "expected = ['Acá', 'te', 'lo', 'aclaro', ':', '\\n', 'de', 'octubre', ':', 'Día', 'de', 'brujas', '(', 'Mujeres', ')', '\\n', 'de', 'noviembre', ':', 'Día', 'de', 'todos', 'los', 'santos', '(', 'Hombres', ')', '\\n', 'noviembre', ':', 'Día', 'de', 'los', 'difuntos', '(', 'Hombres', 'que', 'se', 'animaron', 'a', 'decirle', 'brujas', 'a', 'las', 'mujeres', ')']\n",
    "test_filter_tokens(result, expected)\n",
    "\n",
    "# test Filter.NEWLINE\n",
    "result = filter_tokens(parsed_df['tokens'], [Filter.NEWLINE]).loc[22]\n",
    "expected = ['Sin', 'querer', ',', 'hoy', 'le', 'dije', '“', 'Hola', '”', 'a', 'una', 'feminista', '.', 'El', 'juicio', 'es', 'mañana', '.', 'HASHTAG', '   ', 'feminismo', '  ', '#']\n",
    "test_filter_tokens(result, expected)\n",
    "\n",
    "# test Filter.SPACE\n",
    "result = filter_tokens(parsed_df['tokens'], [Filter.SPACE]).loc[22]\n",
    "expected = ['Sin', 'querer', ',', 'hoy', 'le', 'dije', '“', 'Hola', '”', 'a', 'una', 'feminista', '.', 'El', 'juicio', 'es', 'mañana', '.', '\\n\\n', 'HASHTAG', 'feminismo', '#']\n",
    "\n",
    "# test Filter.TAGS\n",
    "result = filter_tokens(parsed_df['tokens'], [Filter.TAGS]).loc[14869]\n",
    "# FIXME: Notice that when there is no space between `-` and the next word, both are recognized as a single token\n",
    "expected = ['  ', '  ', '  \\n', '-Te', 'cuento', 'un', 'chiste', 'machista', '?', '\\n', '-Pero', 'que', 'dices', ',', 'si', 'soy', 'mujer', '.', '\\n', '-Tranquila', ',', 'te', 'lo', 'explico', '.']\n",
    "test_filter_tokens(result, expected)\n",
    "\n",
    "\n",
    "# test all\n",
    "result = filter_tokens(parsed_df['tokens'], [Filter.PUNCT, Filter.STOPWORDS, Filter.EMOJI, Filter.NUMBER, Filter.NEWLINE, Filter.SPACE]).loc[5245]\n",
    "expected = ['Acá', 'aclaro', 'octubre', 'Día', 'brujas', 'Mujeres', 'noviembre', 'Día', 'santos', 'Hombres', 'noviembre', 'Día', 'difuntos', 'Hombres', 'animaron', 'decirle', 'brujas', 'mujeres']\n",
    "test_filter_tokens(result, expected)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TF-IDF\n",
    "TODO: Try different token filtering options for TF-IDF\n",
    "\n",
    "-wydaje mi sie ze mozna by usunac numery czy jakies znaki specjalne (oprocz ? czy !)\n",
    "\n",
    "-jakies super rzadkie słowa/super czeste słowa usunac lub nie maja znaczenia sentymentalnego\n",
    "\n",
    "-i moze powinno sie sprobowac n-gramów ?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>humor</th>\n",
       "      <th>woman</th>\n",
       "      <th>lgbtiq</th>\n",
       "      <th>race</th>\n",
       "      <th>gordofobia</th>\n",
       "      <th>mean</th>\n",
       "      <th>tokens</th>\n",
       "      <th>processed</th>\n",
       "      <th>tf-idf</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>index</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>MENTION Ya estará colocada en algún chiringuit...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3.4</td>\n",
       "      <td>[MENTION, Ya, estará, colocada, en, algún, chi...</td>\n",
       "      <td>mention colocado alguno chiringuito feminazi</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Sin querer, hoy le dije “Hola” a una feminista...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3.8</td>\n",
       "      <td>[Sin, querer, ,, hoy, le, dije, “, Hola, ”, a,...</td>\n",
       "      <td>querer hoy decir hola feminista juicio mañana ...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>En este capítulo, que se transmitió en el Cana...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.2</td>\n",
       "      <td>[En, este, capítulo, ,, que, se, transmitió, e...</td>\n",
       "      <td>capítulo transmitir canal televisión británico...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>MENTION MENTION MENTION Concuerdo contigo en e...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3.8</td>\n",
       "      <td>[MENTION, MENTION, MENTION, Concuerdo, contigo...</td>\n",
       "      <td>mention mention mention concuerdo contigo supe...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>– ¡No es no! ¡En mi cuerpo mando yo!\\r\\n– ¡Así...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.2</td>\n",
       "      <td>[–, ¡, No, es, no, !, ¡, En, mi, cuerpo, mando...</td>\n",
       "      <td>cuerpo mando así hablar empoderada poder abort...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    text  humor  woman  \\\n",
       "index                                                                    \n",
       "9      MENTION Ya estará colocada en algún chiringuit...      0      1   \n",
       "22     Sin querer, hoy le dije “Hola” a una feminista...      1      1   \n",
       "30     En este capítulo, que se transmitió en el Cana...      0      0   \n",
       "40     MENTION MENTION MENTION Concuerdo contigo en e...      0      0   \n",
       "45     – ¡No es no! ¡En mi cuerpo mando yo!\\r\\n– ¡Así...      1      1   \n",
       "\n",
       "       lgbtiq  race  gordofobia  mean  \\\n",
       "index                                   \n",
       "9           0     0           0   3.4   \n",
       "22          0     0           0   3.8   \n",
       "30          1     0           0   2.2   \n",
       "40          1     0           0   3.8   \n",
       "45          0     0           0   2.2   \n",
       "\n",
       "                                                  tokens  \\\n",
       "index                                                      \n",
       "9      [MENTION, Ya, estará, colocada, en, algún, chi...   \n",
       "22     [Sin, querer, ,, hoy, le, dije, “, Hola, ”, a,...   \n",
       "30     [En, este, capítulo, ,, que, se, transmitió, e...   \n",
       "40     [MENTION, MENTION, MENTION, Concuerdo, contigo...   \n",
       "45     [–, ¡, No, es, no, !, ¡, En, mi, cuerpo, mando...   \n",
       "\n",
       "                                               processed  \\\n",
       "index                                                      \n",
       "9           mention colocado alguno chiringuito feminazi   \n",
       "22     querer hoy decir hola feminista juicio mañana ...   \n",
       "30     capítulo transmitir canal televisión británico...   \n",
       "40     mention mention mention concuerdo contigo supe...   \n",
       "45     cuerpo mando así hablar empoderada poder abort...   \n",
       "\n",
       "                                                  tf-idf  \n",
       "index                                                     \n",
       "9      [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  \n",
       "22     [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  \n",
       "30     [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  \n",
       "40     [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  \n",
       "45     [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Remove stopwords, punctuations, emojis, numbers, newlines and spaces\n",
    "tf_idf_df = parsed_df.copy()\n",
    "tf_idf_df['processed'] = filter_tokens(tf_idf_df['tokens'], [Filter.PUNCT, Filter.STOPWORDS, Filter.EMOJI, Filter.NUMBER, Filter.NEWLINE, Filter.SPACE])\n",
    "\n",
    "# Use lemmas instead of tokens\n",
    "tf_idf_df['processed'] = tf_idf_df['processed'].apply(lambda tokens: [token.lemma_ for token in tokens])\n",
    "\n",
    "# Concat all tokens into a single string\n",
    "# This is needed for the TF-IDF vectorizer\n",
    "tf_idf_df['processed'] = tf_idf_df['processed'].apply(lambda tokens: ' '.join(tokens))\n",
    "\n",
    "# lowercase\n",
    "tf_idf_df['processed'] = tf_idf_df['processed'].apply(lambda tokens: tokens.lower())\n",
    "\n",
    "# TF-IDF vectorizer\n",
    "tf_idf_vectorizer = TfidfVectorizer()\n",
    "tf_idf_df[\"tf-idf\"] = tf_idf_vectorizer.fit_transform(tf_idf_df['processed']).toarray().tolist()\n",
    "\n",
    "display(tf_idf_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of tf-idf vector: 7875\n"
     ]
    }
   ],
   "source": [
    "print(f\"Length of tf-idf vector: {len(tf_idf_df['tf-idf'].iloc[0])}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Word embeddings\n",
    "### FastText Spanish Unannotated Corpora\n",
    "Pre-trained word embeddings were downloaded from [dccuchile/spanish-word-embeddings](https://github.com/dccuchile/spanish-word-embeddings#fasttext-embeddings-from-suc).\n",
    "\n",
    "According to [josecannete/spanish-corpora](https://github.com/josecannete/spanish-corpora) the corpus on which the FastText embeddings were trained was processed in the following way:\n",
    "\n",
    "> - Lowercase\n",
    "> - Removed urls\n",
    "> - Removed listing\n",
    "> - Replaced multiple spaces with single one\n",
    "\n",
    "so in order to get the best results we will need to do the same. Urls in the training set are replaced with the string `URL` but we will remove them anyway. We will do the same for hashtags and mentions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>humor</th>\n",
       "      <th>woman</th>\n",
       "      <th>lgbtiq</th>\n",
       "      <th>race</th>\n",
       "      <th>gordofobia</th>\n",
       "      <th>mean</th>\n",
       "      <th>tokens</th>\n",
       "      <th>processed</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>index</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>MENTION Ya estará colocada en algún chiringuit...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3.4</td>\n",
       "      <td>[MENTION, Ya, estará, colocada, en, algún, chi...</td>\n",
       "      <td>[Ya, estará, colocada, en, algún, chiringuito,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Sin querer, hoy le dije “Hola” a una feminista...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3.8</td>\n",
       "      <td>[Sin, querer, ,, hoy, le, dije, “, Hola, ”, a,...</td>\n",
       "      <td>[Sin, querer, ,, hoy, le, dije, “, Hola, ”, a,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>En este capítulo, que se transmitió en el Cana...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.2</td>\n",
       "      <td>[En, este, capítulo, ,, que, se, transmitió, e...</td>\n",
       "      <td>[En, este, capítulo, ,, que, se, transmitió, e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>MENTION MENTION MENTION Concuerdo contigo en e...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3.8</td>\n",
       "      <td>[MENTION, MENTION, MENTION, Concuerdo, contigo...</td>\n",
       "      <td>[Concuerdo, contigo, en, eso, ,, super, repugn...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>– ¡No es no! ¡En mi cuerpo mando yo!\\r\\n– ¡Así...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.2</td>\n",
       "      <td>[–, ¡, No, es, no, !, ¡, En, mi, cuerpo, mando...</td>\n",
       "      <td>[–, ¡, No, es, no, !, ¡, En, mi, cuerpo, mando...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    text  humor  woman  \\\n",
       "index                                                                    \n",
       "9      MENTION Ya estará colocada en algún chiringuit...      0      1   \n",
       "22     Sin querer, hoy le dije “Hola” a una feminista...      1      1   \n",
       "30     En este capítulo, que se transmitió en el Cana...      0      0   \n",
       "40     MENTION MENTION MENTION Concuerdo contigo en e...      0      0   \n",
       "45     – ¡No es no! ¡En mi cuerpo mando yo!\\r\\n– ¡Así...      1      1   \n",
       "\n",
       "       lgbtiq  race  gordofobia  mean  \\\n",
       "index                                   \n",
       "9           0     0           0   3.4   \n",
       "22          0     0           0   3.8   \n",
       "30          1     0           0   2.2   \n",
       "40          1     0           0   3.8   \n",
       "45          0     0           0   2.2   \n",
       "\n",
       "                                                  tokens  \\\n",
       "index                                                      \n",
       "9      [MENTION, Ya, estará, colocada, en, algún, chi...   \n",
       "22     [Sin, querer, ,, hoy, le, dije, “, Hola, ”, a,...   \n",
       "30     [En, este, capítulo, ,, que, se, transmitió, e...   \n",
       "40     [MENTION, MENTION, MENTION, Concuerdo, contigo...   \n",
       "45     [–, ¡, No, es, no, !, ¡, En, mi, cuerpo, mando...   \n",
       "\n",
       "                                               processed  \n",
       "index                                                     \n",
       "9      [Ya, estará, colocada, en, algún, chiringuito,...  \n",
       "22     [Sin, querer, ,, hoy, le, dije, “, Hola, ”, a,...  \n",
       "30     [En, este, capítulo, ,, que, se, transmitió, e...  \n",
       "40     [Concuerdo, contigo, en, eso, ,, super, repugn...  \n",
       "45     [–, ¡, No, es, no, !, ¡, En, mi, cuerpo, mando...  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fast_text_suc_df = parsed_df.copy()\n",
    "fast_text_suc_df['processed'] = filter_tokens(fast_text_suc_df['tokens'], [Filter.SPACE, Filter.TAGS, Filter.NEWLINE])\n",
    "fast_text_suc_df['processed'] = fast_text_suc_df['processed'].apply(lambda tokens: [token.text for token in tokens])\n",
    "\n",
    "fast_text_suc_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load FastText model\n",
    "FAST_TEXT_SUC_PATH = os.path.join(os.getcwd(), 'embeddings', 'fasttext', 'embeddings-l-model.vec')\n",
    "fast_text_suc_model = KeyedVectors.load_word2vec_format(FAST_TEXT_SUC_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "300\n"
     ]
    }
   ],
   "source": [
    "fast_text_suc_vec_len = len(fast_text_suc_model['hola'])\n",
    "print(fast_text_suc_vec_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Represent each sentence as the average of its word embeddings\n",
    "def get_sentence_embedding(tokens: list[str], model):\n",
    "    embeddings = []\n",
    "    at_least_one = False\n",
    "    for token in tokens:\n",
    "        try:\n",
    "            embeddings.append(model[token])\n",
    "            at_least_one = True\n",
    "        except KeyError:\n",
    "            pass\n",
    "\n",
    "    if not at_least_one:\n",
    "        return np.zeros(fast_text_suc_vec_len)\n",
    "    \n",
    "    return np.mean(embeddings, axis=0)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>humor</th>\n",
       "      <th>woman</th>\n",
       "      <th>lgbtiq</th>\n",
       "      <th>race</th>\n",
       "      <th>gordofobia</th>\n",
       "      <th>mean</th>\n",
       "      <th>tokens</th>\n",
       "      <th>processed</th>\n",
       "      <th>embedding</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>index</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>MENTION Ya estará colocada en algún chiringuit...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3.4</td>\n",
       "      <td>[MENTION, Ya, estará, colocada, en, algún, chi...</td>\n",
       "      <td>[Ya, estará, colocada, en, algún, chiringuito,...</td>\n",
       "      <td>[-0.4105145, -0.476945, 0.033990335, -0.420986...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Sin querer, hoy le dije “Hola” a una feminista...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3.8</td>\n",
       "      <td>[Sin, querer, ,, hoy, le, dije, “, Hola, ”, a,...</td>\n",
       "      <td>[Sin, querer, ,, hoy, le, dije, “, Hola, ”, a,...</td>\n",
       "      <td>[-0.16515553, -0.28686935, -0.049638003, -0.20...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>En este capítulo, que se transmitió en el Cana...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.2</td>\n",
       "      <td>[En, este, capítulo, ,, que, se, transmitió, e...</td>\n",
       "      <td>[En, este, capítulo, ,, que, se, transmitió, e...</td>\n",
       "      <td>[-0.11882315, -0.25109497, -0.058445625, -0.14...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>MENTION MENTION MENTION Concuerdo contigo en e...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3.8</td>\n",
       "      <td>[MENTION, MENTION, MENTION, Concuerdo, contigo...</td>\n",
       "      <td>[Concuerdo, contigo, en, eso, ,, super, repugn...</td>\n",
       "      <td>[-0.17745455, -0.30860102, 0.021036755, -0.256...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>– ¡No es no! ¡En mi cuerpo mando yo!\\r\\n– ¡Así...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.2</td>\n",
       "      <td>[–, ¡, No, es, no, !, ¡, En, mi, cuerpo, mando...</td>\n",
       "      <td>[–, ¡, No, es, no, !, ¡, En, mi, cuerpo, mando...</td>\n",
       "      <td>[-0.18298145, -0.38118437, 0.024085896, -0.004...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    text  humor  woman  \\\n",
       "index                                                                    \n",
       "9      MENTION Ya estará colocada en algún chiringuit...      0      1   \n",
       "22     Sin querer, hoy le dije “Hola” a una feminista...      1      1   \n",
       "30     En este capítulo, que se transmitió en el Cana...      0      0   \n",
       "40     MENTION MENTION MENTION Concuerdo contigo en e...      0      0   \n",
       "45     – ¡No es no! ¡En mi cuerpo mando yo!\\r\\n– ¡Así...      1      1   \n",
       "\n",
       "       lgbtiq  race  gordofobia  mean  \\\n",
       "index                                   \n",
       "9           0     0           0   3.4   \n",
       "22          0     0           0   3.8   \n",
       "30          1     0           0   2.2   \n",
       "40          1     0           0   3.8   \n",
       "45          0     0           0   2.2   \n",
       "\n",
       "                                                  tokens  \\\n",
       "index                                                      \n",
       "9      [MENTION, Ya, estará, colocada, en, algún, chi...   \n",
       "22     [Sin, querer, ,, hoy, le, dije, “, Hola, ”, a,...   \n",
       "30     [En, este, capítulo, ,, que, se, transmitió, e...   \n",
       "40     [MENTION, MENTION, MENTION, Concuerdo, contigo...   \n",
       "45     [–, ¡, No, es, no, !, ¡, En, mi, cuerpo, mando...   \n",
       "\n",
       "                                               processed  \\\n",
       "index                                                      \n",
       "9      [Ya, estará, colocada, en, algún, chiringuito,...   \n",
       "22     [Sin, querer, ,, hoy, le, dije, “, Hola, ”, a,...   \n",
       "30     [En, este, capítulo, ,, que, se, transmitió, e...   \n",
       "40     [Concuerdo, contigo, en, eso, ,, super, repugn...   \n",
       "45     [–, ¡, No, es, no, !, ¡, En, mi, cuerpo, mando...   \n",
       "\n",
       "                                               embedding  \n",
       "index                                                     \n",
       "9      [-0.4105145, -0.476945, 0.033990335, -0.420986...  \n",
       "22     [-0.16515553, -0.28686935, -0.049638003, -0.20...  \n",
       "30     [-0.11882315, -0.25109497, -0.058445625, -0.14...  \n",
       "40     [-0.17745455, -0.30860102, 0.021036755, -0.256...  \n",
       "45     [-0.18298145, -0.38118437, 0.024085896, -0.004...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fast_text_suc_df['embedding'] = fast_text_suc_df['processed'].apply(lambda tokens: get_sentence_embedding(tokens, fast_text_suc_model))\n",
    "display(fast_text_suc_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of FastText embedding vector: 300\n"
     ]
    }
   ],
   "source": [
    "print(f\"Length of FastText embedding vector: {len(fast_text_suc_df['embedding'].iloc[0])}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TODO: Word2Vec\n",
    "Pre-trained word2vec embeddings were downloaded from [aitoralmeida/spanish_word2vec](https://github.com/aitoralmeida/spanish_word2vec).\n",
    "\n",
    "Aitor Almeida, & Aritz Bilbao. (2018). Spanish 3B words Word2Vec Embeddings (Version 1.0) [Data set]. Zenodo. http://doi.org/10.5281/zenodo.1410403\n",
    "Bilbao-Jayo, A., & Almeida, A. (2018). Automatic political discourse analysis with multi-scale convolutional neural networks and contextual data. International Journal of Distributed Sensor Networks, 14(11), 1550147718811827."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://radimrehurek.com/gensim/models/keyedvectors.html\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24\n"
     ]
    }
   ],
   "source": [
    "import gensim.downloader as api\n",
    "from gensim.models import KeyedVectors\n",
    "from gensim.test.utils import lee_corpus_list\n",
    "\n",
    "# Load pre-trained word embeddings\n",
    "# word2vec_path = os.path.join(os.getcwd(), 'embeddings', 'word2vec', 'complete.kv')\n",
    "# KeyedVectors.load('complete.kv', mmap='r')\n",
    "# word2vec_model = KeyedVectors.load_word2vec_format(word2vec_path)\n",
    "model = Word2Vec(lee_corpus_list, vector_size=24, epochs=100)\n",
    "word_vectors = model.wv\n",
    "word_vectors.save('complete.kv') # jest tez vectors.kv\n",
    "word2vec_model = KeyedVectors.load('complete.kv')\n",
    "\n",
    "print(len(word2vec_model['king']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>humor</th>\n",
       "      <th>woman</th>\n",
       "      <th>lgbtiq</th>\n",
       "      <th>race</th>\n",
       "      <th>gordofobia</th>\n",
       "      <th>mean</th>\n",
       "      <th>tokens</th>\n",
       "      <th>processed</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>index</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>MENTION Ya estará colocada en algún chiringuit...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3.4</td>\n",
       "      <td>[MENTION, Ya, estará, colocada, en, algún, chi...</td>\n",
       "      <td>[Ya, estará, colocada, en, algún, chiringuito,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Sin querer, hoy le dije “Hola” a una feminista...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3.8</td>\n",
       "      <td>[Sin, querer, ,, hoy, le, dije, “, Hola, ”, a,...</td>\n",
       "      <td>[Sin, querer, ,, hoy, le, dije, “, Hola, ”, a,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>En este capítulo, que se transmitió en el Cana...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.2</td>\n",
       "      <td>[En, este, capítulo, ,, que, se, transmitió, e...</td>\n",
       "      <td>[En, este, capítulo, ,, que, se, transmitió, e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>MENTION MENTION MENTION Concuerdo contigo en e...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3.8</td>\n",
       "      <td>[MENTION, MENTION, MENTION, Concuerdo, contigo...</td>\n",
       "      <td>[Concuerdo, contigo, en, eso, ,, super, repugn...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>– ¡No es no! ¡En mi cuerpo mando yo!\\r\\n– ¡Así...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.2</td>\n",
       "      <td>[–, ¡, No, es, no, !, ¡, En, mi, cuerpo, mando...</td>\n",
       "      <td>[–, ¡, No, es, no, !, ¡, En, mi, cuerpo, mando...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    text  humor  woman  \\\n",
       "index                                                                    \n",
       "9      MENTION Ya estará colocada en algún chiringuit...      0      1   \n",
       "22     Sin querer, hoy le dije “Hola” a una feminista...      1      1   \n",
       "30     En este capítulo, que se transmitió en el Cana...      0      0   \n",
       "40     MENTION MENTION MENTION Concuerdo contigo en e...      0      0   \n",
       "45     – ¡No es no! ¡En mi cuerpo mando yo!\\r\\n– ¡Así...      1      1   \n",
       "\n",
       "       lgbtiq  race  gordofobia  mean  \\\n",
       "index                                   \n",
       "9           0     0           0   3.4   \n",
       "22          0     0           0   3.8   \n",
       "30          1     0           0   2.2   \n",
       "40          1     0           0   3.8   \n",
       "45          0     0           0   2.2   \n",
       "\n",
       "                                                  tokens  \\\n",
       "index                                                      \n",
       "9      [MENTION, Ya, estará, colocada, en, algún, chi...   \n",
       "22     [Sin, querer, ,, hoy, le, dije, “, Hola, ”, a,...   \n",
       "30     [En, este, capítulo, ,, que, se, transmitió, e...   \n",
       "40     [MENTION, MENTION, MENTION, Concuerdo, contigo...   \n",
       "45     [–, ¡, No, es, no, !, ¡, En, mi, cuerpo, mando...   \n",
       "\n",
       "                                               processed  \n",
       "index                                                     \n",
       "9      [Ya, estará, colocada, en, algún, chiringuito,...  \n",
       "22     [Sin, querer, ,, hoy, le, dije, “, Hola, ”, a,...  \n",
       "30     [En, este, capítulo, ,, que, se, transmitió, e...  \n",
       "40     [Concuerdo, contigo, en, eso, ,, super, repugn...  \n",
       "45     [–, ¡, No, es, no, !, ¡, En, mi, cuerpo, mando...  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word2vec_suc_df = parsed_df.copy()\n",
    "word2vec_suc_df['processed'] = filter_tokens(word2vec_suc_df['tokens'], [Filter.SPACE, Filter.TAGS, Filter.NEWLINE])\n",
    "word2vec_suc_df['processed'] = word2vec_suc_df['processed'].apply(lambda tokens: [token.text for token in tokens])\n",
    "\n",
    "word2vec_suc_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>humor</th>\n",
       "      <th>woman</th>\n",
       "      <th>lgbtiq</th>\n",
       "      <th>race</th>\n",
       "      <th>gordofobia</th>\n",
       "      <th>mean</th>\n",
       "      <th>tokens</th>\n",
       "      <th>processed</th>\n",
       "      <th>embedding</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>index</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>MENTION Ya estará colocada en algún chiringuit...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3.4</td>\n",
       "      <td>[MENTION, Ya, estará, colocada, en, algún, chi...</td>\n",
       "      <td>[Ya, estará, colocada, en, algún, chiringuito,...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Sin querer, hoy le dije “Hola” a una feminista...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3.8</td>\n",
       "      <td>[Sin, querer, ,, hoy, le, dije, “, Hola, ”, a,...</td>\n",
       "      <td>[Sin, querer, ,, hoy, le, dije, “, Hola, ”, a,...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>En este capítulo, que se transmitió en el Cana...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.2</td>\n",
       "      <td>[En, este, capítulo, ,, que, se, transmitió, e...</td>\n",
       "      <td>[En, este, capítulo, ,, que, se, transmitió, e...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>MENTION MENTION MENTION Concuerdo contigo en e...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3.8</td>\n",
       "      <td>[MENTION, MENTION, MENTION, Concuerdo, contigo...</td>\n",
       "      <td>[Concuerdo, contigo, en, eso, ,, super, repugn...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>– ¡No es no! ¡En mi cuerpo mando yo!\\r\\n– ¡Así...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.2</td>\n",
       "      <td>[–, ¡, No, es, no, !, ¡, En, mi, cuerpo, mando...</td>\n",
       "      <td>[–, ¡, No, es, no, !, ¡, En, mi, cuerpo, mando...</td>\n",
       "      <td>[4.9878545, -0.22066407, 1.8122944, 0.47024563...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    text  humor  woman  \\\n",
       "index                                                                    \n",
       "9      MENTION Ya estará colocada en algún chiringuit...      0      1   \n",
       "22     Sin querer, hoy le dije “Hola” a una feminista...      1      1   \n",
       "30     En este capítulo, que se transmitió en el Cana...      0      0   \n",
       "40     MENTION MENTION MENTION Concuerdo contigo en e...      0      0   \n",
       "45     – ¡No es no! ¡En mi cuerpo mando yo!\\r\\n– ¡Así...      1      1   \n",
       "\n",
       "       lgbtiq  race  gordofobia  mean  \\\n",
       "index                                   \n",
       "9           0     0           0   3.4   \n",
       "22          0     0           0   3.8   \n",
       "30          1     0           0   2.2   \n",
       "40          1     0           0   3.8   \n",
       "45          0     0           0   2.2   \n",
       "\n",
       "                                                  tokens  \\\n",
       "index                                                      \n",
       "9      [MENTION, Ya, estará, colocada, en, algún, chi...   \n",
       "22     [Sin, querer, ,, hoy, le, dije, “, Hola, ”, a,...   \n",
       "30     [En, este, capítulo, ,, que, se, transmitió, e...   \n",
       "40     [MENTION, MENTION, MENTION, Concuerdo, contigo...   \n",
       "45     [–, ¡, No, es, no, !, ¡, En, mi, cuerpo, mando...   \n",
       "\n",
       "                                               processed  \\\n",
       "index                                                      \n",
       "9      [Ya, estará, colocada, en, algún, chiringuito,...   \n",
       "22     [Sin, querer, ,, hoy, le, dije, “, Hola, ”, a,...   \n",
       "30     [En, este, capítulo, ,, que, se, transmitió, e...   \n",
       "40     [Concuerdo, contigo, en, eso, ,, super, repugn...   \n",
       "45     [–, ¡, No, es, no, !, ¡, En, mi, cuerpo, mando...   \n",
       "\n",
       "                                               embedding  \n",
       "index                                                     \n",
       "9      [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  \n",
       "22     [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  \n",
       "30     [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  \n",
       "40     [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  \n",
       "45     [4.9878545, -0.22066407, 1.8122944, 0.47024563...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "word2vec_suc_df['embedding'] = word2vec_suc_df['processed'].apply(lambda tokens: get_sentence_embedding(tokens, word2vec_model))\n",
    "display(word2vec_suc_df.head())\n",
    "\n",
    "#tutaj wykorzytsuje te same sposoby na procesowanie tekstu ale nie jestem 100% pewna czy nie ma czegos jeszcze "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TODO: GloVe"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://github.com/sebtheiler/tutorials/blob/main/using-pretrained-glove-vectors/GloVe-tutorial.ipynb\n",
    "\n",
    "https://nlp.stanford.edu/projects/glove/\n",
    "\n",
    "https://machinelearningmastery.com/develop-word-embeddings-python-gensim/\n",
    "\n",
    "https://stackoverflow.com/questions/48962171/how-to-train-glove-algorithm-on-my-own-corpus -> how to train "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sarae\\AppData\\Local\\Temp\\ipykernel_21952\\402147345.py:5: DeprecationWarning: Call to deprecated `glove2word2vec` (KeyedVectors.load_word2vec_format(.., binary=False, no_header=True) loads GLoVE text vectors.).\n",
      "  glove2word2vec(glove_input_file, word2vec_output_file)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(400000, 100)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create file txt.word2vec\n",
    "from gensim.scripts.glove2word2vec import glove2word2vec\n",
    "glove_input_file = 'glove.6B.100d.txt'\n",
    "word2vec_output_file = 'glove.6B.100d.txt.word2vec'\n",
    "glove2word2vec(glove_input_file, word2vec_output_file)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load pre-trained word embeddings\n",
    "glove_path = 'glove.6B.100d.txt.word2vec'\n",
    "glove_model = KeyedVectors.load_word2vec_format(glove_path, binary=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n"
     ]
    }
   ],
   "source": [
    "print(len(glove_model['hola']))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
